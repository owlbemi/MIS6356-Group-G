---
title: 'OPRE6359 Group G Final Project'
subtitle: 'MIS6356.004'
author: "Jake Lee, Mishal Andoor, Vinisha Gunasaleen, Jayveenrhaj Gunasaleen, Nivas Annamareddy, Andrea Ontiveros"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
mainfont: "JetBrains Mono"
---
# Config Git
``git config --global user.name "Your Name"``
``git config --global user.email "your.email@example.com"``

# Required packages

```{r}
# run remotes::install_github("benyamindsmith/RKaggle")
library(RKaggle)
library(dplyr)
library(tidyr)
library(caret)
library(rpart)
library(rpart.plot)
```

# Importing Data

Reference: https://www.kaggle.com/datasets/sahilislam007/ai-impact-on-job-market-20242030

```{r}
raw_df <- get_dataset("sahilislam007/ai-impact-on-job-market-20242030")
```

# Basic Data Cleaning

```{r}
summary(raw_df)

# factorise certain columns

df <- raw_df

cols <- c("Job Status", "Required Education", "AI Impact Level", "Industry")
df[cols] <- lapply(raw_df[cols], as.factor)

# order the factors

df$`AI Impact Level` <- factor(
  df$`AI Impact Level`,
  levels = c("Low", "Moderate", "High"),
  ordered = TRUE
)

df$`Required Education` <- factor(
  df$`Required Education`,
  levels = c("High School", "Associate Degree", "Bachelor’s Degree", "Master’s Degree", "PhD"),
  ordered = TRUE
)

```


```{r}
head(df)

summary(df)
```

```{r}
names(df)
```

# Data Exploration 

```{r}
data <- df

#St Deviation for each numeric variable
sapply(data[, sapply(data, is.numeric)], sd, na.rm = TRUE)


#Identify numeric columns automatically
numeric_data <- data[, sapply(data, is.numeric)]

#Get min, max, mean, quartiles (summary)
summary(numeric_data)


#Get Standard Deviation for each variable
sapply(numeric_data, sd, na.rm = TRUE)

#Step 1: Load Packages 
library(ggplot2)
library(tidyr)
library(dplyr)


#Step 2: Keep only the numeric columns you need
box_data <- data %>%
  select(
  `Median Salary (USD)`,
  `Experience Required (Years)`,
  `Job Openings (2024)`,
  `Projected Openings (2030)`,
  `Remote Work Ratio (%)`,
  `Automation Risk (%)`,
  `Gender Diversity (%)`
)


#Step 3: Reshape data into log format 
box_long <- box_data %>%
  pivot_longer(
    cols = everything(),
    names_to = "Metric",
    values_to = "Value"
)



#Step 4: Create faceted boxplots
ggplot(box_long, aes(x = Metric, y = Value, fill = Metric)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16) +
  facet_wrap(~ Metric, scales = "free", ncol = 3) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "none",
    strip.text = element_text(face = "bold", size = 12),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(
    title = "Distribution of Job Market Metrics",
    y = "Value",
    x = ""
  )

#Step 5: Add annotations or median labels
box_long_summary <- box_long %>%
  group_by(Metric) %>%
  summarize(median_val = median(Value, na.rm = TRUE))

ggplot(box_long, aes(x = Metric, y = Value, fill = Metric)) +
  geom_boxplot(outlier.color = "red") +
  geom_text(
    data = box_long_summary,
    aes(x = Metric, y = median_val, label = round(median_val, 1)),
    color = "black",
    size = 3,
    vjust = -0.7
  ) +
  facet_wrap(~ Metric, scales = "free", ncol = 3) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "none",
    strip.text = element_text(face = "bold")
  ) +
  labs(title = "Faceted Boxplots with Median Values", x = "", y = "Value")

```

# Decision Tree
## Selecting Features

```{r}

# Keep only numeric predictors + target
df_numeric <- df[, c(
  "Job Status",
  "Median Salary (USD)",
  "Experience Required (Years)",
  "Job Openings (2024)",
  "Projected Openings (2030)",
  "Remote Work Ratio (%)",
  "Automation Risk (%)",
  "Gender Diversity (%)"
)]

# Check structure
str(df_numeric)

```
# Plotting and fitting Decision Tree

```{r}

# Split into training and test sets (2/3 training, 1/3 test)
set.seed(345)
train_index <- sample(1:nrow(df_numeric), nrow(df_numeric) * (2/3))
train_data <- df_numeric[train_index, ]
test_data  <- df_numeric[-train_index, ]

# Fit the decision tree
fit_numeric <- rpart(
  `Job Status` ~ ., 
  data = train_data,
  method = "class",
  control = rpart.control(minsplit = 200, cp = 0.001, maxdepth = 4),
  parms = list(split = "gini")
)

# Check the fit
print(fit_numeric)
```
## Accuracy 

```{r}

# Plot the tree
rpart.plot(fit_numeric, type = 1, extra = 2, cex = 0.6)

# Predict on test data and create confusion matrix
jobstatus.pred <- predict(fit_numeric, newdata = test_data, type = "class")
jobstatus.actual <- test_data$`Job Status`
confusion.matrix <- table(jobstatus.pred, jobstatus.actual)
confusion.matrix

# Accuracy on Training Data
jobstatus.pred <- predict(fit_numeric, train_data, type = "class")
jobstatus.actual <- train_data$`Job Status`
train_accuracy <- sum(jobstatus.pred == jobstatus.actual) / nrow(train_data)
print(paste("Training Accuracy:", round(train_accuracy, 3)))


# Accuracy on Testing Data
jobstatus.pred <- predict(fit_numeric, test_data, type = "class")
jobstatus.actual <- test_data$`Job Status`
test_accuracy <- sum(jobstatus.pred == jobstatus.actual) / nrow(test_data)
print(paste("Testing Accuracy:", round(test_accuracy, 3)))

```
# Logistic Regression
## Train / Test Data
  
```{r}
# set random seed for ML
set.seed(2021)

train_index <- sample(1:nrow(df), 0.6 * nrow(df))

train.df <- df[train_index, ]
test.df <- df[-train_index, ]

# Run Logreg

logit.reg <- glm(`Job Status` ~ `AI Impact Level` + `Median Salary (USD)` + `Required Education` + `Experience Required (Years)` + `Job Openings (2024)` + `Projected Openings (2030)` + `Remote Work Ratio (%)` + `Automation Risk (%)` + `Gender Diversity (%)`, 
                 data = train.df, 
                 family = "binomial")

summary(logit.reg)
```

## Prediction

```{r}
logitPredict <- predict(logit.reg, test.df, type = "response")

summary(logitPredict)

logitPredictClass <- ifelse(logitPredict > 0.5, 1, 0)
```

## Confusion Matrix

```{r}
actual <- test.df$`Job Status`
predict <- logitPredictClass
cm <- table(predict, actual)

cm
```

